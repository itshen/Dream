# Dream-v0-Instruct-7B 网页演示应用

这是一个基于Flask和TailwindCSS开发的网页应用，用于展示Dream-v0-Instruct-7B扩散文本生成模型的工作过程。该应用支持实时流式输出，让用户可以观察到扩散模型逐步填充掩码标记的生成过程。

## 功能特点

- 左右两栏布局，左侧控制参数，右侧显示结果
- 支持设置自定义系统提示（System Prompt）
- 实时显示模型生成过程中的每一步迭代
- 高亮显示掩码标记（掩盖的部分）
- 使用SSE（Server-Sent Events）实现流式输出
- 响应式设计，适配不同设备

## 安装与运行

### 环境要求

- Python 3.8+
- CUDA兼容的GPU（推荐8GB+显存）
- PyTorch 2.0+
- Transformers 4.30+

### 依赖安装

```bash
pip install flask torch transformers
```

### 运行应用

1. 确保您的机器满足运行Dream-v0-Instruct-7B的硬件要求
2. 运行Flask应用：

```bash
python app.py
```

3. 在浏览器中访问：`http://127.0.0.1:5000/`

## 使用方法

1. 在"系统提示"文本框中输入系统指令（默认为"You are a helpful assistant."）
2. 在"用户输入"文本框中输入您的问题或指令
3. 根据需要调整高级参数设置
4. 点击"发送"按钮或按回车键提交
5. 观察右侧输出区域，您将看到模型逐步生成文本的过程
6. 每一步生成都会填充一个掩码标记，直到完成整个生成过程
7. 使用"清除"按钮可以清空生成结果

## 高级参数设置

应用提供了多种可调节的参数，以控制生成过程：

- **步骤数(steps)**：扩散时间步数，默认为16
  - 范围：16-1024
  - 更少的步骤生成更快但结果更粗糙，更多的步骤生成更精细但更慢

- **温度(temperature)**：控制生成文本的随机性，默认为0.75
  - 范围：0.0-1.0
  - 较低的值产生更确定性的结果，较高的值产生更多样化的结果

- **top_p**：控制生成文本的多样性，默认为0.7
  - 范围：0.5-1.0
  - 设置为小于1的值时，仅保留最有可能的标记

- **最大生成长度(max_new_tokens)**：控制生成文本的最大长度，默认为512
  - 范围：128-1024

- **采样算法(alg)**：控制标记生成顺序的策略，默认为"entropy"
  - entropy：基于每个标记分布的熵值生成（推荐）
  - origin：纯随机顺序
  - maskgit_plus：基于top1置信度
  - topk_margin：基于边际置信度

- **算法温度(alg_temp)**：在使用基于置信度的策略时添加随机性，默认为0.2
  - 范围：0.0-1.0

## 技术细节

- 前端：HTML + JavaScript + TailwindCSS
- 后端：Flask
- 实时通信：Server-Sent Events (SSE)
- 模型：Dream-v0-Instruct-7B (扩散型文本生成模型)
- 智能提前结束：当连续20次迭代无文本变化时，自动停止生成

## 注意事项

- 首次运行时，应用会自动下载模型权重（约14GB），请确保有足够的存储空间和网络带宽
- 生成过程可能需要较长时间，取决于您的硬件性能和输入长度
- 减少步骤数可以显著加快生成速度，但可能影响生成质量
- 如果生成内容在一段时间内不再变化，系统会自动提前结束生成过程

## 自定义设置

如需进一步修改默认参数或调整应用，可以编辑以下文件：

- `app.py`：后端Flask应用，包含模型加载和文本生成逻辑
- `templates/index.html`：前端界面和交互逻辑

## 模型信息

Dream-v0-Instruct-7B是一个基于扩散过程的文本生成模型，由香港大学自然语言处理小组(HKUNLP)开发。与传统的自回归语言模型不同，该模型使用基于掩码的非自回归生成方法，允许通过迭代扩散过程生成文本。

项目地址：[https://github.com/HKUNLP/Dream](https://github.com/HKUNLP/Dream)